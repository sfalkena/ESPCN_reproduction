{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ESPCN_reproduction.ipynb","provenance":[],"collapsed_sections":["MUe-sNyYEtXz","cM9ut5Utqedc","Y-3ucPJyhHbE","lreAOdKntZx8","O7S9BxrbFOhk","67c_d_O2p2aw"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MUe-sNyYEtXz"},"source":["---\n","\n","# Running the experiment on Google Colab\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EB5FxQuGFNMD","colab":{}},"source":["from torchvision import transforms\n","from google.colab import drive\n","from torch.utils import data\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","import PIL.Image as pil_image\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import torch\n","import time\n","import cv2\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4n_lwVSHyt6u","colab_type":"code","outputId":"920ef6d6-4a84-42b3-8a98-d45d430dc7a4","executionInfo":{"status":"ok","timestamp":1587387769750,"user_tz":-120,"elapsed":741,"user":{"displayName":"Sieger Falkena","photoUrl":"","userId":"16977573620042866490"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["drive.mount('/content/gdrive')\n","path ='/content/gdrive/My Drive/deep_learning_group_7/Final'\n","os.chdir(path)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BcDCkYFThjkw","colab_type":"code","outputId":"3b297bdf-8317-42d1-a43a-1b22db882a3c","executionInfo":{"status":"ok","timestamp":1587387837064,"user_tz":-120,"elapsed":1430,"user":{"displayName":"Sieger Falkena","photoUrl":"","userId":"16977573620042866490"}},"colab":{"base_uri":"https://localhost:8080/","height":409}},"source":["from IPython.display import HTML\n","HTML(filename = path + '/interactive_image.html')"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<!DOCTYPE html>\n","<html>\n","<head>\n","<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n","<style>\n","* {box-sizing: border-box;}\n","\n",".img-comp-container {\n","  position: relative;\n","  height: 300px; /*should be the same height as the images*/\n","}\n","\n",".img-comp-img {\n","  position: absolute;\n","  width: auto;\n","  height: auto;\n","  overflow:hidden;\n","}\n","\n",".img-comp-img img {\n","  display:block;\n","  vertical-align:middle;\n","}\n","\n",".img-comp-slider {\n","  position: absolute;\n","  z-index:9;\n","  cursor: ew-resize;\n","  /*set the appearance of the slider:*/\n","  width: 40px;\n","  height: 40px;\n","  background-color: #2196F3;\n","  opacity: 0.7;\n","  border-radius: 50%;\n","}\n","\n",".column {\n","  float: left;\n","  width: 33.33%;\n","  padding: 5px;\n","}\n","\n","/* Clear floats after image containers */\n",".row::after {\n","  content: \"\";\n","  clear: both;\n","  display: table;\n","}\n","\n","</style>\n","<script>\n","function initComparisons() {\n","  var x, i;\n","  /*find all elements with an \"overlay\" class:*/\n","  x = document.getElementsByClassName(\"img-comp-overlay\");\n","  for (i = 0; i < x.length; i++) {\n","    /*once for each \"overlay\" element:\n","    pass the \"overlay\" element as a parameter when executing the compareImages function:*/\n","    compareImages(x[i]);\n","  }\n","  function compareImages(img) {\n","    var slider, img, clicked = 0, w, h;\n","    /*get the width and height of the img element*/\n","    w = img.offsetWidth;\n","    h = img.offsetHeight;\n","    /*set the width of the img element to 50%:*/\n","    img.style.width = (w / 2) + \"px\";\n","    /*create slider:*/\n","    slider = document.createElement(\"DIV\");\n","    slider.setAttribute(\"class\", \"img-comp-slider\");\n","    /*insert slider*/\n","    img.parentElement.insertBefore(slider, img);\n","    /*position the slider in the middle:*/\n","    slider.style.top = (h / 2) - (slider.offsetHeight / 2) + \"px\";\n","    slider.style.left = (w / 2) - (slider.offsetWidth / 2) + \"px\";\n","    /*execute a function when the mouse button is pressed:*/\n","    slider.addEventListener(\"mousedown\", slideReady);\n","    /*and another function when the mouse button is released:*/\n","    window.addEventListener(\"mouseup\", slideFinish);\n","    /*or touched (for touch screens:*/\n","    slider.addEventListener(\"touchstart\", slideReady);\n","    /*and released (for touch screens:*/\n","    window.addEventListener(\"touchstop\", slideFinish);\n","    function slideReady(e) {\n","      /*prevent any other actions that may occur when moving over the image:*/\n","      e.preventDefault();\n","      /*the slider is now clicked and ready to move:*/\n","      clicked = 1;\n","      /*execute a function when the slider is moved:*/\n","      window.addEventListener(\"mousemove\", slideMove);\n","      window.addEventListener(\"touchmove\", slideMove);\n","    }\n","    function slideFinish() {\n","      /*the slider is no longer clicked:*/\n","      clicked = 0;\n","    }\n","    function slideMove(e) {\n","      var pos;\n","      /*if the slider is no longer clicked, exit this function:*/\n","      if (clicked == 0) return false;\n","      /*get the cursor's x position:*/\n","      pos = getCursorPos(e)\n","      /*prevent the slider from being positioned outside the image:*/\n","      if (pos < 0) pos = 0;\n","      if (pos > w) pos = w;\n","      /*execute a function that will resize the overlay image according to the cursor:*/\n","      slide(pos);\n","    }\n","    function getCursorPos(e) {\n","      var a, x = 0;\n","      e = e || window.event;\n","      /*get the x positions of the image:*/\n","      a = img.getBoundingClientRect();\n","      /*calculate the cursor's x coordinate, relative to the image:*/\n","      x = e.pageX - a.left;\n","      /*consider any page scrolling:*/\n","      x = x - window.pageXOffset;\n","      return x;\n","    }\n","    function slide(x) {\n","      /*resize the image:*/\n","      img.style.width = x + \"px\";\n","      /*position the slider:*/\n","      slider.style.left = img.offsetWidth - (slider.offsetWidth / 2) + \"px\";\n","    }\n","  }\n","}\n","</script>\n","</head>\n","<body>\n","\n","<h1>Comparison of low resolution and upscaled image</h1>\n","\n","<p>Click and slide the blue slider to compare two images:</p>\n","\n","<div class= \"row\">\n","  <div class=\"column\">\n","    <div class=\"img-comp-container\">\n","      <div class=\"img-comp-img\">\n","        <img src=\"https://drive.google.com/uc?id=1UMlytPGnyvrqLXtOVv5Fc2ONBirju3cc\" width=\"450\" height=\"300\">\n","      </div>\n","      <div class=\"img-comp-img img-comp-overlay\">\n","        <img src=\"https://drive.google.com/uc?id=1lDOdjfHbB5Ag2yTQ4Oj_9QfSN6Fzvyvb\" width=\"450\" height=\"300\">\n","      </div>\n","    </div>\n","  </div>\n","  <div class=\"column\">\n","    <div class=\"img-comp-container\">\n","      <div class=\"https://drive.google.com/uc?id=1d9wcBNyQutZ0Av9Llh_6y5Ll7qQmDWXE\" width=\"450\" height=\"300\">\n","      </div>\n","      <div class=\"img-comp-img img-comp-overlay\">\n","        <img src=\"https://drive.google.com/uc?id=1Vtwkf9oVRK2zhEqaBJGs2SJcix3lXb0N\" width=\"450\" height=\"300\">\n","      </div>\n","    </div>\n","  </div>\n","</div>\n","\n","\n","<script>\n","/*Execute a function that will execute an image compare function for each element with the img-comp-overlay class:*/\n","initComparisons();\n","</script>\n","\n","</body>\n","</html>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cM9ut5Utqedc"},"source":["# ESPCN Architecture\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lmSYnMfYGtlJ","outputId":"090b12de-f221-4894-ba80-60e786dd2692","executionInfo":{"status":"ok","timestamp":1587376177583,"user_tz":-120,"elapsed":982,"user":{"displayName":"Luc Kloosterman","photoUrl":"","userId":"16495140397496214217"}},"colab":{"base_uri":"https://localhost:8080/","height":145}},"source":["r = 3 #scaling factor\n","\n","class SuperResConvNet(nn.Module):\n","  def __init__(self):\n","    'Initialize layers'\n","    super(SuperResConvNet, self).__init__()\n","    self.conv1 = nn.Conv2d(1,64, kernel_size=5, stride=1, padding=2)\n","    self.conv2 = nn.Conv2d(64,32, kernel_size=3, stride=1, padding=1)\n","    self.conv3 = nn.Conv2d(32,1*r**2, kernel_size=3, stride=1, padding=1)\n","    self.upsample = nn.PixelShuffle(r)\n","\n","  def forward(self, y):\n","    'Define forward pass'\n","    y = torch.tanh(self.conv1(y))\n","    y = torch.tanh(self.conv2(y))\n","    y = self.conv3(y)\n","    y = self.upsample(y)\n","    return y\n","\n","# Check for GPU availibility\n","if torch.cuda.is_available():\n","  print(\"Using GPU\")\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define model and send to device\n","ConvNet = SuperResConvNet()\n","ConvNet.to(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using GPU\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SuperResConvNet(\n","  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (upsample): PixelShuffle(upscale_factor=3)\n",")"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"Y-3ucPJyhHbE","colab_type":"text"},"source":["#Functions"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P0boumoCMCIC","outputId":"2a260dca-d9ab-4d80-8d45-733d812dd350","executionInfo":{"status":"ok","timestamp":1587376045662,"user_tz":-120,"elapsed":1388,"user":{"displayName":"Luc Kloosterman","photoUrl":"","userId":"16495140397496214217"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Define directories\n","slide_subfolders = ['yang91/T91/', #trainingset\n","                    'x3.0/Set5/', 'x3.0/Set14/', # Testsets\n","                    'x3.0/BSD300/', 'x3.0/BSD500/', 'x3.0/SuperText136/'] \n","\n","#width and height of patches\n","x = 17      \n","\n","class Slide:\n","  'Combines functions for loading and preparing images for training and testing'\n","  def __init__(self, path, slide_subfolders, count):\n","    self.count = count\n","    self.dir = path + '/CVPR2016_ESPCN_OurBenchMarkResult/Ours/' + slide_subfolders\n","    \n","    self.namelist = self.deleteLRImage()\n","    if count == 0:\n","        self.patchlist = self.patchlist_get()\n","      \n","  def removePng(f):\n","    'returns filename without png'\n","    filename_parts = f[:-4]\n","    return filename_parts\n","\n","  def getList(self):\n","    'returns list of filenames' \n","    return [Slide.removePng(f) for f in os.listdir(self.dir) if f.endswith(\".png\")]\n","\n","  def deleteLRImage(self):\n","    'deletes LR images from list if they are already made (which they are)'\n","    name_list_2 = Slide.getList(self)\n","    name_list_1 = [x for x in name_list_2 if \"lr\" not in x ]\n","    name_list =  [x for x in name_list_1 if \"lowRes\" not in x ]\n","    return name_list\n","  \n","  def getPatchList(self, img_name):\n","    'returns patch list of one image'\n","    #get filenames and load images\n","    filename = self.dir + img_name\n","    lr_img = cv2.cvtColor(cv2.imread(filename+'_lr.png'), cv2.COLOR_BGR2RGB)\n","\n","    #parameters \n","    stride_lr = x-np.sum((5%2,3%2,3%2))\n","    tot_img_d = int(lr_img.shape[0]/stride_lr), int(lr_img.shape[1]/stride_lr)    #amount of image in height and width respectively\n","    tot_img = tot_img_d[0]*tot_img_d[1]     #total amount of images\n","\n","    #create list for current image\n","    patch_list = []\n","    for i in range(tot_img_d[0]-1):\n","        for j in range(tot_img_d[1]-1):\n","            patch_list.append([img_name, i,j])\n","    return patch_list\n","  \n","  def patchlist_get(self):\n","    'create patch_list'\n","    patch_list = []\n","    for i in range(len(self.namelist)):\n","        patch_list.extend(self.getPatchList(self.namelist[i]))\n","    print('Found', len(patch_list), 'trainable patches out of', len(self.namelist), 'images.')\n","    return patch_list\n","  \n","  def createPatch(self, name):\n","    'returns a patch'\n","    img_name = name[0]\n","    patch_name = name[1], name[2]\n","\n","    #get corresponding images\n","    filename = self.dir + img_name\n","    hr_img = cv2.cvtColor(cv2.imread(filename+'.png'), cv2.COLOR_BGR2YCrCb)[:,:,0] # only get Y channel from YCrCb\n","    lr_img = cv2.cvtColor(cv2.imread(filename+'_lr.png'), cv2.COLOR_BGR2YCR_CB)[:,:,0]\n","\n","    #create hr patch \n","    stride_hr = (x-np.sum((5%2,3%2,3%2)))*r\n","    hr_patch = hr_img[stride_hr*patch_name[0]:(stride_hr*patch_name[0]+17*r),stride_hr*patch_name[1]:(stride_hr*patch_name[1]+17*r)]\n","\n","    #create lr patch \n","    stride_lr = x-np.sum((5%2,3%2,3%2))\n","    lr_patch = lr_img[stride_lr*patch_name[0]:(stride_lr*patch_name[0]+17),stride_lr*patch_name[1]:(stride_lr*patch_name[1]+17)]\n","\n","    return lr_patch, hr_patch\n","\n","  def bicubic_upsampling(self, img_n):\n","    'Loading high and low resolution image and do a bicubic upsampling of the low resolution image'\n","    #get corresponding images\n","    filename = self.dir + img_n\n","    hr_img = Image.open(filename + '.png').convert('YCbCr')\n","    lr_img = Image.open(filename[:-9] + '-lowRes.png').convert('YCbCr')\n","\n","    #upsample\n","    bicubic = lr_img.resize(hr_img.size, Image.BICUBIC)\n","\n","    return lr_img, bicubic, hr_img # return as pil images\n","\n","def getSlideList(slide_subfolders, path):\n","  'Load Slide class for different directories'\n","  slides = []\n","  for i, slide in enumerate(slide_subfolders):\n","    slides.append(Slide(path, slide, i))\n","  return slides\n","\n","slides = getSlideList(slide_subfolders, path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 1734 trainable patches out of 91 images.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lreAOdKntZx8"},"source":["### PSNR calculation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xq-fvSjktYfs","colab":{}},"source":["def psnr_from_mselist(mse_list):\n","  'Calculate PSNR'\n","  mse = np.mean(mse_list)\n","  if mse == 0:\n","    return float('inf')\n","  else:\n","    return 20*np.log10(255/np.sqrt(mse))\n","\n","def calc_mse(img_pred, img_hr):\n","  'Calculate MSE'\n","  return np.mean((img_pred*255 - img_hr*255)**2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"O7S9BxrbFOhk"},"source":["# Obtaining low resolution images"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zMct6mkQlnwD","colab":{}},"source":["## ONLY RUN THIS CELL IF LOW RESOLUTION IMAGES ARE NOT PRESENT IN THE DIRECTORY\n","def createLowRes(img_name, dir_91):\n","  'saves low resolution image'\n","  # Call HR image\n","  filename = dir_91 + img_name + '.png'\n","  hr_img = cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB)\n","\n","  # Blur HR image\n","  blur_img = cv2.GaussianBlur(hr_img,(5,5),0)\n","\n","  # Apply subsampling\n","  lr_img = blur_img[::r,::r]\n","\n","  # Save lr_img\n","  im = Image.fromarray(lr_img)\n","  im.save(dir_91 + img_name + '_lr.png')\n","\n","for i in range(len(slides[0].namelist)):\n","  dir_91 = path + '/CVPR2016_ESPCN_OurBenchMarkResult/Ours/' + slide_subfolders[0]\n","  createLowRes(slides[0].namelist[i], dir_91)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"67c_d_O2p2aw"},"source":["---\n","# Training\n"]},{"cell_type":"markdown","metadata":{"id":"7NeDugNcgrwV","colab_type":"text"},"source":["##Hyperparameter settings"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gcBec_ZGpwSE","colab":{}},"source":["# Loss and optimizer\n","criterion = nn.MSELoss()     \n","optimizer = torch.optim.Adam(ConvNet.parameters(), lr=0.01)  \n","\n","# Parameters\n","num_epoch = 5000        #Amount of epochs\n","batch_size = 16         #Batch size\n","train_val_ratio = 0.95  #Training validation ratio\n","\n","# Scheduler for dynamic reduction of the learning rate\n","threshold_mu = 1e-6     # Treshold for decreasing learning rate.\n","factor_value = 0.8     # Amount of decay per step, new lr = factor_value*lr.\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n","                                                       mode='min',\n","                                                       factor=factor_value,\n","                                                       patience=2,\n","                                                       threshold=threshold_mu,\n","                                                       min_lr=0.0001,\n","                                                       eps=1e-08,\n","                                                       verbose=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cn9sTJfSZU0t"},"source":["--- \n","### Data loader"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XoHMVNvCZw9-","colab":{}},"source":["class DataGenerator(data.Dataset):\n","  'Generates the dataset that is used for training the ESPCN'\n","  def __init__(self, slides):\n","    self.slides = slides\n","    self.transform = torchvision.transforms.Compose([\n","        torchvision.transforms.ToTensor()])\n","\n","  def __len__(self):\n","    'Returns the amount of patches'\n","    return len(self.slides.patchlist)\n","\n","  def __getitem__(self, idx):\n","    'Returns low and high resolution patches in the form of tensors'\n","    lr_patch, hr_patch = self.slides.createPatch(self.slides.patchlist[idx])\n","    \n","    # transform images to pytorch tensors\n","    lr_patch = self.transform(lr_patch)\n","    hr_patch = self.transform(hr_patch)\n","\n","    return lr_patch, hr_patch   \n","\n","# Put DataGenerator in DataLoader\n","full_dataset = DataGenerator(slides[0])\n","\n","# Split between training and validation set\n","train_size = int(train_val_ratio * len(full_dataset))\n","validation_size = len(full_dataset) - train_size\n","training_set, validation_set = torch.utils.data.random_split(full_dataset, [train_size, validation_size])\n","\n","# Create training and validation data loaders\n","training_generator      = data.DataLoader(training_set, batch_size=batch_size, num_workers=batch_size, shuffle='True')\n","validation_generator    = data.DataLoader(validation_set, batch_size=1, num_workers=1, shuffle='False')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NDRaaKFtkZfr","colab_type":"text"},"source":["### Training the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Acbybp4KqT9j","colab":{}},"source":["# Initializing lists used for saving losses and PSNR\n","loss_list = []\n","epoch_loss_list = []\n","val_loss_list = []\n","validation_psnr = []\n","\n","# Start timer\n","t0 = time.time()\n","\n","# Training loop\n","for epoch in range(num_epoch):\n","  # Switch to training mode\n","  ConvNet.train()\n","  for i, (lr_patch, hr_patch) in enumerate(training_generator):\n","      \n","    # Transfer training data to active device\n","    lr_patch, hr_patch = lr_patch.to(device), hr_patch.to(device)\n","    \n","    # Run the forward pass\n","    outputs = ConvNet(lr_patch)\n","    loss = criterion(outputs, hr_patch)\n","    loss_list.append(loss.item())\n","\n","    # Backprop and perform Adam optimisation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  # Save loss every epoch\n","  epoch_loss = np.sum(loss_list)/len(training_generator)\n","  epoch_loss_list.append(epoch_loss)\n","\n","  # Print epoch loss every 50 epochs\n","  if epoch % 50 == 0:\n","    print(\"Epoch\", epoch, \"loss: {}\".format(epoch_loss))\n","  \n","  # Save model every 1000 epochs (in case Google Colab stops runtime)\n","  # if epoch % 1000 == 999:\n","  #   model_name = 'final_' + str(epoch+1) + '_epochs'\n","  #   path_model = path + '/saved_models/' + model_name\n","  #   torch.save(ConvNet.state_dict(), path_model)\n","  #   print('Model saved as: ', model_name)\n","\n","  # Step to next step of lr-scheduler\n","  scheduler.step(epoch_loss)\n","  loss_list = []\n","\n","  # Enter validation mode\n","  ConvNet.eval()\n","\n","  # Keep track of mse for every patch, to collectively calculate PSNR per epoch\n","  epoch_mse = []\n","  with torch.no_grad():\n","    for i, (lr_patch, hr_patch) in enumerate(validation_generator):\n","      # Transfer training data to active device (GPU)\n","      lr_patch, hr_patch = lr_patch.to(device), hr_patch.to(device)\n","\n","      # Predict output\n","      img_pred = ConvNet(lr_patch)\n","      \n","      # Calculate validation loss\n","      loss = criterion(img_pred, hr_patch)\n","      loss_list.append(loss.item())\n","      \n","      # Calculate mse for every sample \n","      img_pred = img_pred[0].cpu().numpy()\n","      hr_patch = hr_patch[0].cpu().numpy()\n","      epoch_mse.append(calc_mse(img_pred, hr_patch))\n","\n","    # Calculate validation psnr on the complete epoch from all individual MSE's\n","    val_psnr = psnr_from_mselist(np.array(epoch_mse))\n","    validation_psnr.append(val_psnr)\n","  \n","  # Save validation loss every epoch\n","  val_loss = np.sum(loss_list)/len(validation_generator)\n","  val_loss_list.append(val_loss)\n","  \n","  loss_list = []\n","\n","print('Training took {} seconds'.format(time.time() - t0))\n","print('Seconds per epoch:',(time.time()-t0)/num_epoch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Ya3uJQhkfBJ","colab_type":"text"},"source":["### Plot training results"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"r6UHT2xf_2A6","colab":{}},"source":["# Show training and validation loss of current model in memory\n","plt.figure(figsize=(8,8))\n","plt.subplot(2,1,1)\n","plt.title('Loss per epoch')\n","plt.plot(np.arange(num_epoch), epoch_loss_list, label='Training loss')\n","plt.plot(np.arange(num_epoch), val_loss_list, label='Validation loss')\n","plt.yscale(\"log\")\n","plt.legend()\n","\n","plt.subplot(2,1,2)\n","plt.title('PSNR for validation data')\n","plt.plot(np.arange(num_epoch), validation_psnr)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CKboRpOesOnI"},"source":["# Testing\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CVp0obPJDdL9"},"source":["#### Loading the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"odfKMQPuDdUU","outputId":"b914b655-cec9-4765-e1bc-ae3382605f3c","executionInfo":{"status":"ok","timestamp":1587378128268,"user_tz":-120,"elapsed":1017,"user":{"displayName":"Luc Kloosterman","photoUrl":"","userId":"16495140397496214217"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Load weight in earlier defined model\n","model_name = 'final_test_5000_epochsweights'\n","path_model = path + '/saved_models/' + model_name\n","ConvNet.load_state_dict(torch.load(path_model))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"markdown","metadata":{"id":"8rZWqi7Tllsu","colab_type":"text"},"source":["###Test image plot function"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jfdJqCxnG6Dj","colab":{}},"source":["def generate_figure(lr_img, sr_img, hr_img):\n","  'Show the low resolution, upscaled and high resolution image'\n","  f = plt.figure(figsize=(8*3,8))\n","  f.add_subplot(1, 3, 1)\n","  plt.imshow(transforms.ToPILImage('YCbCr')(lr_img[0]).convert('RGB'))\n","  f.add_subplot(1, 3, 2)\n","  plt.imshow(transforms.ToPILImage('YCbCr')(sr_img[0]).convert('RGB'))\n","  f.add_subplot(1, 3, 3)\n","  plt.imshow(transforms.ToPILImage('YCbCr')(hr_img[0]).convert('RGB')) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8ID93xmdDTf8"},"source":["####Data loader"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AuX2RB-qDshU","colab":{}},"source":["class DataGenerator_test(data.Dataset):\n","  'Generates the dataset used for testing'\n","\n","  def __init__(self, slides):\n","    self.slides = slides\n","    self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n","\n","  def __len__(self):\n","    'Returns the amount of test images'\n","    return len(self.slides.namelist)\n","\n","  def __getitem__(self, idx):\n","    'Returns low, upsampled and high resolution testing images in the form of tensors'\n","    lr_img, bicubic, hr_img = self.slides.bicubic_upsampling(self.slides.namelist[idx])\n","    \n","    lr_img = self.transform(lr_img)\n","    hr_img = self.transform(hr_img)\n","    bicubic = self.transform(bicubic)\n","\n","    return lr_img, bicubic, hr_img\n","\n","## Put DataGenerator in DataLoader\n","def DataGenerator(slides):\n","  'Create dataloader for every test directory'\n","  test_set = DataGenerator_test(slides)\n","  test_generator = data.DataLoader(test_set, batch_size=1, shuffle=False)\n","  return test_generator"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mf0k-NdFmniU","colab_type":"text"},"source":["###Testing the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pBZ_7UqRDztA","outputId":"ffc50a82-5557-4163-d20c-b6ee10bd256a","executionInfo":{"status":"ok","timestamp":1587383279988,"user_tz":-120,"elapsed":30757,"user":{"displayName":"Luc Kloosterman","photoUrl":"","userId":"16495140397496214217"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1qIQ8JgQfMM-B9p9fk11OY6vjKk6GFK-V"}},"source":["import random as rnd\n","rnd.seed(9)\n","\n","# Loop over test data sets\n","for j in range(len(slides[1:])):\n","\n","  # Load data\n","  test_generator = DataGenerator(slides[j+1])\n","\n","  show = rnd.randint(0,len(test_generator))\n","\n","  # Define lists\n","  outputs = []\n","  mse_list = []\n","  time_list = []\n","\n","  # Main testing loop\n","  for i, (lr_img, bicubic, hr_img) in enumerate(test_generator):\n","    with torch.no_grad():\n","        \n","      # Only test on the Y (intensity channel)\n","      to_network = (lr_img[:,0,:,:]).unsqueeze(0)\n","\n","      # Start timer\n","      start_time = time.time()\n","      \n","      # Run the forward pass\n","      outputs = ConvNet.cpu()(to_network)\n","      img_pred = outputs[0]\n","\n","      # Substitute the Y channel from bicubic with the one outputted by the model\n","      bicubic[:,0,:,:] = img_pred\n","\n","      #Stop timer\n","      elapsed_time = time.time() - start_time\n","      time_list.append(elapsed_time)\n","\n","      # Calculate MSE\n","      mse = calc_mse(img_pred.numpy(), hr_img.numpy()[:,0,:,:])\n","      mse_list.append(mse.item())\n","\n","      #Show one random image from every dataset\n","      if i == show:\n","        generate_figure(lr_img, bicubic, hr_img)\n","\n","  # Printing the results\n","  print(slide_subfolders[j+1], ': PSNR', psnr_from_mselist(mse_list), 'Average time' ,np.mean(time_list))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}